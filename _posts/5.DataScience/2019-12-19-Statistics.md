---
category : DataScience
tags:
- statistics
- DataScience
---

# 통계

## 경우의 수

### 순열(Permutation)

**서로 다른** n개의 원소에서 **중복없이** r개를 **순서에 상관있게** 택하는 방법

$$
\begin{align}
_nP_r &= n \cdot _{n-1}P_{r-1} \\
&= n \times (n-1) \times (n-2) \times \dots \times (n - r + 1) \\
&= \frac{n!}{(n-r)!}
\end{align}
$$



### 중복순열

**서로 다른** n개의 원소에서 **중복을 허락**하여 r개를 **순서에 상관있게**택하는 방법

$$
_n\Pi_r = n^r
$$



### 조합(Combination)

**서로 다른** n개의 원소에서 **중복없이** r개를 **순서에 상관없이** r개를 택하는 방법

$$
_nC_r = \frac{_nP_r}{r!} = \frac{n!}{(n-r)!r!}
$$



### 중복조합

**서로 다른** n개의 원소에서 **중복을 허락**하여 r개를 **순서에 상관없이** 택하는 조합

$$
\begin{align}
_nH_r = _{n+r-1}C_r
\end{align}
$$



n개의 원소와 분류하는 칸막이 r-1개를 나열한다고 생각하면 쉬움



| 경우의수 | 중복 | 순서 |
| :------: | :--: | :--: |
|   순열   |  X   |  O   |
| 중복순열 |  O   |  O   |
|   조합   |  X   |  X   |
| 중복조합 |  O   |  X   |



## 확률





## 통계적 추론

통계적 추론(statistical inference) : 모집단에 대한 어떤 **미지의 양상**을 알기 위해 통계학을 이용하여 **추측**하는 과정

### 추정과 가설검정

추정은 표본을 통해 모집단 특성이 어떠한가에 대해 추측이고, 가설검정은 추정에 의해 나온 주장을 표본이 가지고 있는 정보를 이용해 가설이 올바른지 판정하는 과정이다.

### 베이즈 추론

베이즈 추론(Bayesian inference) : 통계적 추론의 한 방법으로, 추론 대상의 사전확률과 추가적인 정보를 통해 해당 대상의 사후확률을 추론하는 방법. 베이즈 확률론을 기반으로 하며, 추론하는 대상을 확률변수로 보아 그 변수의 확률분포를 추정하는 것을 의미한다.

베이즈 확률론 : 확률을 '지식 또는 믿음의 정도를 나타내는 양'으로 해석하는 확률론(다른 방법으로 빈도론 이있다.)

H : 가설

D : 데이터

베이즈 정리에 따라 다음과 같다.

$$
P(H|D) = \frac{P(D|H)P(H)}{P(D)}
$$

- `P(H|D)` : 사후확률(posterior)
- `P(H)` : 사전확률(prior)
- `P(D|H)` : 가능도(likelihood)
- `P(D)` : 정규화 상수(normalizing constant) 또는 증거(evidence)

베이즈 추론에서는 추론 대상($$\theta$$)에 대하여, $$\theta$$에대한 사전 확률 $$p(\theta)$$가 주어진다. $$\theta$$와 관계된 관측 X의 확률 분포가 $$p(X \vert \theta)$$ 와 같이 주어진다고 할 때, 베이즈 추론은 X가 추가적으로 주어졌을 떄의 $$\theta$$의 분포 $$p(\theta \vert X)$$는 베이즈 정리를 이용하여 다음과 같이 계산할 수 있다.
$$
p(\theta|X) = \frac{p(\theta,X)}{p(X)} = \frac{p(X|\theta)p(\theta)}{p(X)}
$$



## 기술통계학(Descriptive statistics)

측정이나 실험에서 수집한 자료의 정리, 표현, 요약, 해석 등을 통해 자료의 특성을 규명하는 통계적 방법

### 대표값

- 평균

  - 산술평균
  - 기하평균
  - 조화평균 -> 비율의평균, 속도평균

  $$
  \frac{1}{v_m} = \frac{1}{2} \Big{(} \frac{1}{v_1} + \frac{1}{v_2} \Big{)}
  $$

- 중앙값

- 최빈값

- 사분위수



### 산포

- 절대적인 분포의 산포도
  - 범위
  - 평균편차
  - 사분편차
  - 표준편차, 분산

$$
Variance(x) = \frac{1}{N} \sum^N_{i=1} (x_i - \bar{x})^2
$$

- 상대적인 분포의 산포도
  - 변동계수
  - 사분위편차계수
  - 평균편차계수
- 적률



### 분포의 모양

- 왜도
- 첨도



### 공분산과 상관계수

- 공분산
- 상관계수



### 이산확률 분포

- 이항분포(Binomial)

  n번 시행시, A가 x번 발생할 확률

  $$B(n, p) =(^n_x)p^x(1-p)^{n-x}$$

  평균은 np, 분산은 np(1-p)

- 프아송분포(Poisson)

  확률변수의 기대값과 분산은 모두 람다($$\lambda$$), 이항분포의 특수형태(n이 매우크고, p가 매우 작을 때)

- 초기하분포(Hypergeometric)

- 기하분포(Geometric)

- 음이항분포(Negative binomial)



### 연속확률분포

- 정규분포

- 지수분포

  한 사건이 발생한 이후, 다음 사건이 발생할 때까지의 시간에 대한 확률분포

정규분포를 따르는 모집단에서 추출한 표본분포

- 카이제곱분포

  확률분포에서 나온 확률변수의 제곱의 합

  정규분포의 분산이 그리는 분포와 같다

- t-분포

  표본의 평균이 갖는 분포

  평균은 아는데 분산을 모를때, 모평균을 추정함


- F-분포




# 데이터 과학을 위한 통계

아래 내용은 [데이터 과학을 위한 통계, 한빛미디어, 피터 브루스, 앤드루 브루스 지음, 이준용 옮김] 을 공부하고 요약한 내용입니다.

## 탐색적 데이터 분석

데이터의 종류

- 연속형 : 일정 범위 안에 어떤 값이든 취할 수 있는 데이터 (구간,실수,수치 형)
- 이산 : 정수 값만 취함 (정수형, 횟수)
- 범주형 : 범주 안의 값 (목록, 열거, 등)
- 이진 : 두개의 값만 갖는 범주형 데이터 (이항적, 논리형)
- 순서형 : 값들 사이에 분명한 순위가 있는 범주형 데이터

데이터 처리를 위해 남/여 같은 이진 데이터도 0/1 같이 수치화 해줘야한다.

테이블 데이터 용어

- 데이터 프레임 : 통계와 머신러닝 모델의 기본이되는 테이블 형태의 데이터 구조
- 피처 : 테이블의 각 열 하나 (특징, 속성, 입력, 예측변수)
- 결과 : (종속변수, 응답, 출력)
- 레코드 : 테이블의 각 행 (기록값, 사건, 관측값)



### 위치 추정

데이터를 살펴보는 방법의 기초적 단계는 '대표값(typical value)'를 구하는 것

대푯값: 대부분의 값이 어디쯤에 위치하는지 나타내는 추정값

- 평균(mean)
- 가중평균 : 가중치를 곱한 값의 총합을 가중치의 총합으로 나눈 값
- 중간값(median) : 데이터에서 가장 가운데 위치한 값 (50번쨰 백분위수)
- 가중 중간값 : 데이터 정렬 후 각 가중치 값을 더해서 총합의 중간이 위치하는 데이터 값
- 절사평균 : 극단값을 제외한 나머지 값의 평균

로버스트하다 : 극단값들에 민감하지 않다 (저항성 있다)

특잇값 : 대부분의 값과 매우 다른 데이터값 (극단값)

극단값은 데이터 분석에 있어 유익한 정보를 제공할때도 있고, 골칫거리가 되기도 한다. 평균은 계산하기 쉽고 사용하기 편하지만 극단값의 영향을 많이 받는다. 그래서 보다 전사평균, 가중평균이 더 합리적일 수 있다. 또한 중간값은 데이터의 민감도가 낮기 떄문에 특잇값에 로버스트하다.



### 변이 추정

산포지표(variability) : 데이터의 산포도(dispersion)을 나타내줌

- 편차(deviation) : 관측값과 위치 추정값사이의 차이 (오차, 잔차)
- 분산(variance) : 편균과의 편차를 제곱한 값들의 합을 (데이터개수-1)로 나눈값
- 표준편차 : 분산의 제곱근
- 평균 절대 편차 : 평균과의 편차의 절댓값 평균
- 중앙값 절대편차(MAD) : 중간값과의 편차의 절댓값의 중간값
- 백분위수(percentile) : 어떤 값들을 정렬했을 때 위치하는 순서를 백분위로 나타낸 값 
- 사분위범위(IQR) : 75 백분위수와 25 백분위수 의 차이



표본 분산을 구할때 n-1을 나누는 이유는 자유도(DOF) 때문이다. 표준편차는 표본의 평균에 따른다는 제약 조건을 가지고 있기 때문에 n-1의 자유도를 갖는다. 이를 자세히 알기위해서는 다소 많은 시간을 투자해야하므로 직관적으로 이해하고 넘어간다. 표본집단의 분산으로 모집단의 분산을 추정할때는 n대신 n-1을 나눠야 비편향(unbiased) 추정이라고 알아두고 넘어간다.

표준편차는 원래데이터와 같은 scale에 있고, 수학적으로 제곱한 값이 절댓값보다 통계 모델을 다루는데 더 편리하기때문에 통계에서는 표준편차를 선호한다.

분산, 표준편차, 평균절대편차는 모두 극단값에 로버스트하지 않다. 로버스트한 변위 추정값으로는 MAD, IQR가 있다. 변위(산포지표)를 측정하는 가장 대표적인 방법은 사분위범위(IQR) 이다.

데이터가 매우클때 IQR은 정렬해야하기때문에 연산이 많이필요하다. 그래서 실제로 소프트웨어로 근사값을 이용하는데 꽤 높은 정확도를 보장한다고한다.



### 데이터 분포 탐색하기

데이터 분포를 그래프로 나타내는 방법

- 상자그림boxplot
- 도수분포표frequency table
- 히스토그램histogram
- 밀도 그림density plot



이차, 삼차 모멘트

- 왜도skewness : 데이터가 큰 값이나 작은 값 쪽으로 얼마나 비스듬히 쏠려 있는지 나타내는 값
- 첨도kurtosis : 데이터가 극단값을 갖는 경향성



### 이진데이터와 범주 데이터 탐색

- 최빈값mode
- 기댓값 : 범주의 출현 확률에 따른 평균
- 막대도표
- 파이그림

범주형 데이터는 비율로 요약하고, 막대도표로 나타낸다.



### 상관관계

- 상관계수
- 산점도



## 데이터와 표본분포

### 랜덤표본추출과 표본 편향

- 표본 : 더 큰 데이터 집합으로부터 얻은 부분집합
- 모집단 : 더 큰 데이터 집합
- 랜덤표본추출 : 대상이 되는 모집단 내의 선택 가능한 원소들을 무작위로 추출하는 과정을 말하며, 각 추첨에서 모든 원소는 동일한 확률로 뽑히게 된다.
- 모집단 : 어떤 데이터 집합을 구성하는 전체 대상 혹은 전체집합
- 표본편향 : 모집단을 잘못 대표하는 표본



### 선택편향

편향은 측정이나 관측에 계통적 오차가 있어 전체 모집단을 제대로 대표하지 못할 경우 발생한다.



### 표본분포

- 표본통계량 : 더 큰 모집단에서 추출된 표본 데이터들로부터 얻은 측정 지표
- 표본분포 : 여러 표본들 혹은 재표본들로부터 얻은 표본통계량의 도수분포
- 표준오차 : 여러 표본들로부터 얻은 **표본통계량**의 변량



### 부트스트랩

분류 및 회기 트리(의사결정트리)를 사용할 떄, 여러 부트스트랩 샘플 가지고 트리를 여러개 만들어 각 트리에서 나온 예측값을 평균내는것이 단일 트리 예측보다 효과적이다.

- 부트스트랩 : 관측 데이터 집합으로부터 얻은 **복원추출** 표본
- 재표집 (리샘플링) : 관측 데이터로부터 반복해서 표본추출하는 과정, 부트스트랩 + 셔플링.



### 신뢰구간



### 정규분포

- 표준화(정규화) : 평균을 빼고 표준편차로 나눈다.
- z 점수(z-score) : 개별 데이터 포인트를 정규화한 결과
- 표준정규분포 : 평균 = 0, 표준편차 = 1 인 정규분포
- QQ그림 : 표본분포가 정규분포에 얼마나 가까운지 보여주는 그림



### 긴꼬리분포



### t-분포

표본평균의 분포는 일반적으로 t-분포와 같은 모양이다.

- t-분포 : 정규분포와 비슷하지만, 꼬리 부분이 약간 더 두껍고 길다.



### 이항분포

- 시행(trial) : 독립된 결과를 가져오는 하나의 사건
- 이항식(binormail) : 두가지 결과를 갖는다.
- 이항시행(binomial trial) : 두가지 결과를 가져오는 시행(베르누이 시행)
- 이항분포(binomial distribution) : x번 시행에서 성공한 횟수에 대한 분포(베르누이 분포)



### 이외 분포

- 람다(lambda) : 단위 시간이나 단위 면적당 사건이 발생하는 비율
- 푸아송 분포(poisson distribution) : 표집된 단위 시간 혹은 단위 공간에서 발생한 사건의 도수분포



## 통계적 실험과 유의성 검정

### A/B검정

두 처리 방법, 제품, 혹은 절차 중 어느 쪽이 다른 쪽보다 더 우월하다는 것을 입증하기 위해 실험군을 두 그룹으로 나누어 진행하는 실험.

- 처리 : 어떤 대상에 주어지는 특별한 환경이나 조건
- 처리군 : 특정 처리에 노출된 대상들의 집단
- 대조군 : 어떤 처리도 하지 않은 대상들의 집단
- 대상 : 처리를 적용할 개체 대상
- 검정통계량 : 처리 효과를 측정하기 위한 지표



### 가설검정

- 귀무가설
- 대립가설
- 일원검정
- 이원검정



### 재표본추출



### 통계적 유의성과 p값

통계적 유의성 : 통계학자가 자신의 실험 결과가 우연히 일어난것인지 아니면 우연히 일어날 수 없는 극단적인 것인지를 판단하는 방법

- p값 : 귀무가설을 구체화한 기회 모델이 주어졌을 때, 관측된 결과와 같이 특이하거나 극단적인 결과를 얻을 확률
- 알파 : 실제 결과가 통계적으로 의미 있는 것으로 간주되기 위해, 우연에 의한 기회 결과가 능가해야 하는 '비정상적인' 가능성의 임계확률
- 제1종 오류 : 우연에 의한 효과가 실제 효과라고 잘못 결론 내리는 것
- 제2종 오류 : 실제 효과를 우연에 의한 효과라고 잘못 결론 내리는 것



### t 검정

유의성 검정 방법중 하나

- 검정통계량 : 관심의 차이 또는 효과에 대한 측정 지표
- t 통계량 : 표준화된 형태의 검정통계량
- t 분포 : 관측된 t 통계량을 비교할 수 있는, 기준 분포. ?표본집단의 평균의 분포



### 다중검정



### 자유도



### 분산분석



### 카이제곱검정

일반적으로 변수 간 독립성에 대한 귀무가설이 타당한지를 평가하기 위해 r x c 분할표를 함께 사용.

- 카이제곱통계량 : 기댓값으로부터 어떤 관찰값까지의 거리를 나타내는 측정치
- 기댓값 : 어떤 가정으로부터 데이터가 발생할 때, 그에 대해 기대하는 정도



## 회귀와 예측

**회귀**라는 용어는 일반적으로 선형회귀를 의미하며, 예측변수와 수치형 출력값 사이의 관계를 설명하는 선형모형을 만드는 것에 초점을 둔다. (예측값이 이진형 혹은 범주형일 때는 이와 구분해 '분류'라고 부른다).

머신러닝, 선형회귀에서는 모든문제를 여러변수의 1차 방정식으로 만들어서 y(나중에 예측할)값과 여러개의 x_i(데이터)값이 주어져있으면 이를 모델로 가장 적합한 변수를 찾아간다. 상수마저 x_i가 1이고 계수가 있는 것으로 변환해서 $$y = w * x + \epsilon$$ 로 나타낼 수 있다. 이를 다중 선형회귀라고 한다.



### 단순선형회귀

상관관계가 두 변수 사이의 전체적인 관련 강도를 측정하는 것이라면, 회귀는 관계 자체를 정량화하는 방법이다.

- 응답변수(반응변수) : 예측하고자 하는 변수(Y)
- 독립변수 : 응답치를 예측하기 위해 사용되는 변수(X)
- 레코드 : 한 특정 경우에 대한 입력과 출력을 담고 있는 벡터
- 절편 : 회귀직선의 절편, 즉 X=0일 때 예측값
- 회귀계수 : 회귀직선의 기울기
- 적합값 : 회귀선으로부터 얻은 추정치 $$\hat{Y}_i$$(예측값)
- 잔차 : 관측값과 적합값의 차이(오차)
- 최소제곱 : 잔차의 제곱합을 최소화하여 회귀를 피팅하는 방법



회귀분석에서 중요한 개념은 **적합값**과 **잔차**이다.

#### 적합값

$$ \hat Y = a + b X  $$

- $$ \hat Y $$ : 종속변수 Y의 추정치
- X : 독립변수
- a : $$ \hat Y $$ 축 절편
- b  : 직선의 기울기

$$
b = \frac{n \sum_{i=1}^n X_i Y_i - (\sum_{i=1}^n X_i)(\sum_{i=1}^n Y_i)}{n\sum_{i=1}^n X_i^2 - (\sum_{i=1}^n X)^2}
$$

$$
a = \frac {\sum_{i=1}^n Y_i - b \sum_{i=1}^n X_i} {n}
$$







$$\hat{Y}_i = \hat{b}_0 + \hat{b}_1 X_i$$

$$\hat{Y}_i$$ : 적합값, 예측값

$$X_i$$ : 데이터

$$\hat{ }$$ 은 추정치를 나타낸다.




#### 잔차

잔차 $$\hat{e}_i = Y_i - \hat{Y}_i$$



#### 최소제곱회귀

실무에서 회귀선은 잔차들을 제곱한 값들의 합인 잔차제곱합(RSS : Residual Sum of Squares)을 최소화한는 선이다.

$$
\begin{align}
RSS &= \sum_{i=1}^{n}(Y_i - \hat{Y}_i)^2 \\
&= \sum_{i=1}^{n}(Y_i - \hat{b}_0 - \hat{b}_1 X_i)^2 \\
\end{align}
$$

이때 추정치 $$\hat{b}_0$$ 와 $$\hat{b}_1$$는 RSS를 최소화하는 값이다. 이렇게 잔차제곱합을 최소화하는 방법을 최소제곱회귀 혹은 보통최소제곱(OLS)회귀라고 한다.



### 다중선형회귀

에측변수가 여러개

$$Y = b_0 + b_1 X_1 + b_2 X_2 + \dots + b_p X_p + e$$

오차를 측정하는 방법

- 제곱근 평균제곱오차(RMSE) : 회귀 시 평균제곱오차의 제곱근. 회귀모형을 평가하는 데 가장 널리 사용되는 측정 지표

  $$RMSE = \sqrt{\frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n}}$$

- 잔차 표준오차(RSE) : 평균제곱오차를 자유도에 따라 보정한 값

  $$RSE = \sqrt{\frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{(n-p-1)}}$$

- R 제곱 : 0에서 1까지 모델에 의해 설명된 분산의 비율. 모델 데이터의 변동률 측정

  $$R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y}_i)^2}$$

- t 통계량 : 계수의 표준오차로 나눈 예측변수의 계수. 모델에서 변수의 중요도를 비교하는 기준

- 가중회귀 : 다른 가중치를 가진 레코드들을 회귀하는 방법



### 회귀를 이용한 예측

데이터 과학에서 회귀의 주된 목적은 **예측**이다.

- 예측구간 : 개별 예측값 주위의 불확실한 구간
- 외삽법 : 모델링에 사용된 데이터 범위를 벗어난 부분까지 모델을 확장, 위험성이 높음



### 회귀에서의 요인변수

요인변수(factor variable)는 개수가 제한된 이산값을 취한다. 이중 지표변수(indicator variable)(이진변수)는 요인변수의 특수한 경우이다. 이러한 요인변수를 회귀분석하기위해서 일반적으로 이진 가변수들의 집합으로 변환한다.

- 가변수 : 요인 데이터를 0과 1의 이진변수로 부호화한 변수
- 기준 부호화 : 한 요인을 기준으로 하고 다른 요인들이 이 기준에 따라 비교할 수 있도록 한 형태. 통계학자들이 많이 사용.
- 원-핫 인코딩 : 머신러닝 분야에서 많이 사용. 다중선형회귀에 적합하지 않음.
- 편차 부호화



### 회귀방정식 해석

- 변수 간 상관 : 예측변수들끼리 높은 상관성을 갖을 때, 개별 계수를 해석하는 것은 어려움
- 다중공선성 : 예측변수끼리 거의 완벽한 상관성을 가지면 회귀는 불안정하고 계산이 불가능
- 교란변수 : 중요하지만 누락되어 잘못된 결과를 이끄는 예측변수
- 주효과 : 다른 변수들과 독립된, 하나의 예측변수와 결과변수 사이의 관계
- 상호작용 : 둘 이상의 예측변수와 응답변수 사이의 상호 의존적인관계



### 가정 검정: 회귀 진단

- 표준화잔차
- 특잇값
- 영향값
- 지렛대(레버리지)
- 비정규 잔차
- 이분산성
- 편잔차그림



### 다항회귀와 스플라인 회귀



## 분류(classification)

분류 문제는 데이터가 0인지 1인지 판단하거나, 각 클래스에 속할 예측 확률을 구하는 것이다. 

### 나이브 베이즈

나이브 베이즈(naive Bayes) 알고리즘은 주어진 결과에 대해 예측변수 값을 관찰할 확률을 사용하여, 범주형 예측변수가 주어졌을 때, 범주형 결과 Y = i 를 관찰할 확률을 추정한다.

- 조건부확률 : 어떤 사건(Y=i)이 주어졌을 때, 해당 사건(X=i)을 관찰할 확률 $$P(X_i \mid Y_i)$$
- 사후확률 : 예측 정보를 통합한 후 결과의 확률 (사전확률은 예측변수에 대한 정보 고려X)

나이브하지 않은 베이지언 분류는 표본에서 새로운 레코드와 정확히 일치하는 데이터를 찾는 것에 무게를 두는 방식이다. 하지만 예측변수의 개수가 어느정도 커지면 완전히 일치하는 경우가 거의 없다.

나이브 베이즈 방법은 전체 데이터에서 각 예측변수에 대한 조건부확률을 이용해서 예측변수에 대해 가장 높은 확률을 갖는 클래스를 해당 레코드에 할당하는 방법이다. 단, 예측변수들은 서로 독립이어야 한다.



### 판별분석

- 공분산 : 하나의 변수가 다른 변수와 함께 변화하는 정도를 측정하는 지표
- 판별함수 : 예측변수에 적용했을 때, 클래스 구분을 최대화하는 함수
- 판별 가중치 : 판별함수를 적용하여 얻은 점수를 말하며, 어떤 클래스에 속할 확률을 추정하는 데 사용된다.

판별분석에 가장 일반적으로 사용되는 것은 선형판별분석(LDA)이다. (최근엔 더 정교한 트리모델이나 로지스틱 회귀 사용)

공분산이란 두변수 x와 z 사이의 관계를 의미하는 지표이다.

$$
\begin{align}
s_{x,z} = \frac{ \sum_{i=1}^{n} (x_i - \bar{x}) (z_i - \bar{z}) }{n-1}
\end{align}
$$

상관계수가 -1에서 1사이에 정의됐다면, 공분산은 변수 x와 z에서 사용하는 척도와 동일한 척도에서 정의된다. x와 z에 대한 공분산행렬은 다음과 같다.

$$
\hat{\sum} =
\begin{pmatrix}
s_x^2 & s_{x,z} \\
s_{x,z} & s_z^2 
\end{pmatrix}
$$

피셔의 선형판별은 그룹 안의 편차와 다른 그룹 간의 편차를 구분한다. LDA를 기본으로 한며, 레코드를 두 그룹으로 나누는 방법을 찾기위해 내부제곱합에 대한 사이제곱합의 비율을 최대화 하는것을 목표로한다.



## 로지스틱 회귀

결과가 이진형 변수인 다중선형회귀와 비슷하다. 구조화된 모델 접근 방식이라고 할 수 있다. 빠른 계산 속도와 새로운 데이터에 대한 빠른 점수 산정 덕분에 다양한 분야에서 사용한다.

- 로짓 : $$\pm \infty$$ 의 범위에서 어떤 클래스에 속할 확률을 결정하는 함수
- 오즈 : 실패에 대한 성공의 비율
- 로그 오즈 : 변환 모델의 응답변수. 이값을 통해 확률을 구한다.

핵심 구성 요소는 **로지스틱 반응 함수**와 **로짓** 이다. 다음과 같은 선형함수는 0과 1사이로 딱 떨어뜨리기 힘들기 때문에 확률을 만들기 힘들다. 

$$
p = b_0 + b_1 x_1 + b_2 x_2 + \dots + b_q x_q
$$

대신, 예측변수에 로지스틱 반응 혹은 역 로짓 함수라는 것을 적용해서 p를 모델링한다.

$$
\begin{align}
p = \frac{1}{1+e^{-(b_0+b_1 x_1 + b_2 x_w + \dots + b_q x_q)}}
\end{align}
$$

분모의 지수는 오즈비를 이용해서

$$
log(오즈(Y = 1)) = b_0 + b_1 x_1 + b_2 x_2 + \dots + b_q x_q
$$

위와같은 로그 오즈 함수 또는 로짓함수를 구할 수 있다.

선형회귀를 확장한 일반화선형모형(GLM)은 회귀와 함께 두 번째로 가장 중요한 모델이다.



### 분류 모델 평가하기

- 정확도
- 혼동행렬
- 민감도
- 특이도
- 정밀도
- ROC 곡선
- 리프트





## 통계적 머신러닝



### K 최근접 이웃(K-nearst neighbors)(KNN)

특징들이 가장 유사한 K개의 레코드를 찾아 이유사한 레코들 중 다수가 속한 클래스를 찾고(분류), 유사한 레코드들의 평균을 찾아서 새로운 레코드에 대한 예측값으로 사용(예측)한다.

- 이웃 : 예측변수에서 값들이 유사한 레코드
- 거리 지표 : 각 레코드 사이가 얼마다 멀리 떨어져 있는지 나타내는 값. 
- 표준화 : 평균을 뺀 후에 표준편차로 나누는일(정규화)
- z-점수 : 표준화를 통해 얻은 값
- K : 최근접 이웃을 계산하는 데 사용되는 이웃의 개수



#### 거리지표

- 유클리드 거리 : 직선거리
- 멘하탄 거리



#### 원-핫 인코더

요인 변수를 이진 가변수의 집합으로 변환



#### 표준화(정규화, z점수)

얼마나 평균과 차이가 나는지 관심을 가질떄 필요



#### K선택하기

K가 작을수록 가장 가까운 데이터를 찾아 예측 결과로 사용한다. 하지만 노이즈에 민감해 오버피팅 문제가 발생한다.



### 트리 모델

트리 모델은 의사 결정 트리(decision tree)라고도 불리며 효과적인 분류(및 회귀) 방법이다.  

- 재귀 분할 : 마지막 분할 영역에 해당하는 출력이 최대한 비슷한 결과를 보이도록 데이터를 반복적으로 분할하는 것
- 분할 값 : 분할 값을 기준으로 예측변수를 그 값보다 작은 영역과 큰 영역으로 나눈다.
- 마디
- 잎
- 손실 : 분류하는 과정에서 발생하는 오분류의 수, 손실이 클수록 불순도가 높다고 할 수 있다.
- 분순도 : 데이터를 분할한 집합에서 서로 다른 클래스의 데이터가 얼마나 섞여 있는지를 나타냄



### 배깅과 랜덤 포레스트

- 앙상블(ensemble) : 여러 모델의 집합을 이용해서 하나의 예측을 이끌어내는 방식
- 배깅(bagging) : 데이터를 부트스트래핑해서 여러 모델을 만드는 일반적인 방법
- 랜덤 포레스트 : 의사 경정 트리 모델에 기반을 둔 배깅 추정 모델

앙상블 모델은 많은 모델로부터 얻은 결과를 서로 결합해 모델 정확도를 높인다. 배깅은 앙상블 모델 가운데 하나의 형태로, 부트스트랩 샘플을 이용해 많은 모델들을 생성하고 이 모델들을 평균화한다. 랜덤 포레스트는 데이터를 재표본추출하는 동시에 트리를 분할할 떄 예측변수 또한 샘플링한다.



#### 배깅



#### 랜덤 포레스트



### 부스팅

모델들을 앙상블 형태로 만들기 위한 일반적인 기법.

- 에이다부스트
- 그레이디언트 부스팅
- 확률적 그레디언트 부스팅

