

### 데이터 셋 구성방법

- Holdout : 데이터 셋의 일부를 훈련용 데이터, 나머지 일부를 테스트용 데이터로 구성 (train set, test set), train set이 작으면 모델 정확도의 분산이 커지고, train set이 커지면 test set의 정확도의 신뢰도가 하락
- Cross validation : 중복되지 않는 k개의 부분 셋으로 나누어 구성
- K fold cross validation : data set을 K개의 fold로 나누어 사용. K번의 실험을 진행하여 k-1개 fold는 training set, 1개는 test set으로 사용.
- Stratified sampling : 각 클래스로부터 일정 비율의 샘플 추출 하는 층별 표집 방법. 데이터를 클래스에 따라 그룹으로 분리하고, 각 그룹으로 일정 비율 샘플을 무작위로 추출. 전체 데이터에서 표본이 특정 클래스에 편중될 수 있는 단점을 보완.



### 적합도 검증

표본회귀식이 종소변수의 값을 어느 정도 정확하게 예측할 수 있는지 검증 (모델 성능 평가 척도)

- Confusion matrix : 모델의 성능을 통계적인 수치로 시각화. 실제값과 예측값의 빈도를 표로 나타내줌

  | .        | 예측 yes           | 예측 no            |
  | -------- | ------------------ | ------------------ |
  | 실제 yes | TP(True Positive)  | FN(False Negative) |
  | 실제 no  | FP(False Positive) | TN(True Negative)  |

- Accuracy : 모델이 정확하게 분류 또는 예측하는 데이터의 비율. 가장 직관적이지만 domain bias 고려해야함.

  $$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

- Precision(정밀도) : 모델이 True라고 분류한것중 실제 True의 비율

  $$Precision = \frac{TP}{TP + FP}$$

- Recall(재현율) : 실제 True중 모델이 True라고 예측한 비율

  $$Recall = \frac{TP}{TP+FN}$$

- **F-Measure** : Precision과 Recall을 통합(조화평균)해 나타내는 정확도

  $$ F-measure = \frac{2rp}{r+p} = \frac{2TP}{2TP+FN+FP}$$

- ROC Curve : 민감도와 특이도의 관계 파악하는 그래프

  TPR / FPR 그래프

  $$TPR=\frac{T P}{P}$$, $$FPR =\frac{FP}{FP +TN}$$

- AUC

- Residual(잔차) : 회귀 분석 모델의 예측값과 실제 값의 차이

- MSE : 평균제곱오차

- RMSE : 모델 예측값의 오차 계산

참고 : https://sumniya.tistory.com/26

- 추정의 표준오차
- 결정계수

#### 추정의 표준오차

추정의 표준오차 : 표본들의 실제 값들이 표본회귀선 주위로 흩어진 변동 측정

표준편차 : 표본의 실제 값들이 평균주위로 흩어진 변동 측정



잔차들의 표준편차를 구함
$$
S_e = \sqrt\frac{ \sum(y_i - \hat{y}_i)^2}{n-2} = \sqrt\frac{SSE}{n-2} = \frac{\sum{y^2} - a \sum{y}- b \sum{xy}}{n-2}
$$
SSE : 오차제곱합 : (진짜값 - 예측값)^2

$$SSE = \sum (y_i - \hat{y}_i)^2$$

추정 표준오차 계산 기준은 회귀직선, 절편과 기울기의 두 통게량에 의해 결정되므로 자유도는 2만큼 감소



#### 결정계수

결정계수를 구하기 위해서는 아래 값을 먼저 알아야한다.

- SST : 실제 값 $$y_i$$ 들이 이들의 평균 $$\bar y$$ 로부터 흩어진 정도
- SSR : 예측치와 실제 값 $$y_i$$ 들의 평균 $$\bar y$$ 의 차이의 제곱의 합
- SSE : 예측치와 실제 값의 차이의 제곱의 합

$$ SST = \sum(y_i - \bar y)^2$$

$$ SSR = \sum(\hat y_i - \bar y)^2$$

$$SSE = \sum (y_i - \hat{y}_i)^2$$

SST는 다음과 같은 과정을 통해

$$
\begin{align}
(y_i - \bar y)^2 &= (y_i - \hat y_i + \hat y_i - \bar y )^2 \\
				&= ((y_i - \hat y_i) + (\hat y_i - \bar y) )^2 \\
				&= (y_i - y)^2 + (\hat y_i - \bar y)^2 + 2 (y_i - y) (\hat y_i - \bar y) \\
				&\approx (y_i - y)^2 + (\hat y_i - \bar y)^2 \\
				&(\because 2 (y_i - y) (\hat y_i - \bar y) \approx 0)
\end{align}
$$

아래와 같이 나타낼 수 있다.


$$
\begin{align}
SST = SSE + SSR
\end{align}
$$

즉, 총제곱합(SST) = 회귀제곱합(SSR) + 잔차제곱합(SSE)

SST 는 항상 SSE보다 크거나 같다

![SSESSR](../assets/img/SSESSR.png)

$$Rsqure = \frac{SSR}{SST} = \frac{(예측 - 진짜평균)^2}{(진짜-진짜평균)^2}$$

$$ r^2 = \frac{SST - SSE}{SST} = 1 - \frac{SSE}{SST}$$



$$\frac{SSE}{SST}$$ 이

0 일떄 : SSE가 0이면 => 다맞춤

1 일때 : SSE == SST 일때 => 최대로 틀렸을때



그래서 결정계수 R_square은 0부터 1값을 갖고, 1에 가까울 수록 좋다는 것을 알 수 있다.







조정 결정계수

데이터 개수 n 이 많고 독립변수 수 K 가 작을수록 좋다 -> 수식으로 만듬
$$
R_a^2 = 1 - (1 - R^2) (\frac{n-1}{n-k-1})
$$






























회귀와 분류

머신러닝의 할일은 크게 두가지

A와 B의 차이를 구분하는 분류

A집단이 어떠한 경향을 갖는지 알아내는 회귀

