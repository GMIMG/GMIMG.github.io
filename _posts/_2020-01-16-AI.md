

데이터 셋 구성방법

- Holdout : 데이터 셋의 일부를 훈련용 데이터, 나머지 일부를 테스트용 데이터로 구성 (train set, test set), train set이 작으면 모델 정확도의 분산이 커지고, train set이 커지면 test set의 정확도의 신뢰도가 하락
- Cross validation : 중복되지 않는 k개의 부분 셋으로 나누어 구성
- K fold cross validation : data set을 K개의 fold로 나누어 사용. K번의 실험을 진행하여 k-1개 fold는 training set, 1개는 test set으로 사용.
- Stratified sampling : 각 클래스로부터 일정 비율의 샘플 추출 하는 층별 표집 방법. 데이터를 클래스에 따라 그룹으로 분리하고, 각 그룹으로 일정 비율 샘플을 무작위로 추출. 전체 데이터에서 표본이 특정 클래스에 편중될 수 있는 단점을 보완.



모델 성능 평가 척도

- Confusion matrix : 모델의 성능을 통계적인 수치로 시각화. 실제값과 예측값의 빈도를 표로 나타내줌

  | .        | 예측 yes           | 예측 no            |
  | -------- | ------------------ | ------------------ |
  | 실제 yes | TP(True Positive)  | FN(False Negative) |
  | 실제 no  | FP(False Positive) | TN(True Negative)  |

- Accuracy : 모델이 정확하게 분류 또는 예측하는 데이터의 비율. 가장 직관적이지만 domain bias 고려해야함.

  $$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

- Precision(정밀도) : 모델이 True라고 분류한것중 실제 True의 비율

  $$Precision = \frac{TP}{TP + FP}$$

- Recall(재현율) : 실제 True중 모델이 True라고 예측한 비율

  $$Recall = \frac{TP}{TP+FN}$$

- F-Measure : Precision과 Recall을 통합(조화평균)해 나타내는 정확도

  $$ F-measure = \frac{2rp}{r+p} = \frac{2TP}{2TP+FN+FP}$$

- ROC Curve : 민감도와 특이도의 관계 파악하는 그래프

  TPR / FPR 그래프

  $$TPR=\frac{T P}{P}$$, $$FPR =\frac{FP}{FP +TN}$$

- Residual(잔차) : 회귀 분석 모델의 예측값과 실제 값의 차이

- MSE : 평균제곱오차

- RMSE : 모델 예측값의 오차 계산

참고 : https://sumniya.tistory.com/26