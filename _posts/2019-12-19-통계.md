---

---

# 통계

## 경우의 수

### 순열(Permutation)

**서로 다른** n개의 원소에서 **중복없이** r개를 **순서에 상관있게** 택하는 방법
$$
\begin{align}
_nP_r &= n \cdot _{n-1}P_{r-1} \\
&= n \times (n-1) \times (n-2) \times \dots \times (n - r + 1) \\
&= \frac{n!}{(n-r)!}
\end{align}
$$



### 중복순열

**서로 다른** n개의 원소에서 **중복을 허락**하여 r개를 **순서에 상관있게**택하는 방법
$$
_n\Pi_r = n^r
$$



### 조합(Combination)

**서로 다른** n개의 원소에서 **중복없이** r개를 **순서에 상관없이** r개를 택하는 방법
$$
_nC_r = \frac{_nP_r}{r!} = \frac{n!}{(n-r)!r!}
$$



### 중복조합

**서로 다른** n개의 원소에서 **중복을 허락**하여 r개를 **순서에 상관없이** 택하는 조합
$$
\begin{align}
_nH_r = _{n+r-1}C_r
\end{align}
$$



n개의 원소와 분류하는 칸막이 r-1개를 나열한다고 생각하면 쉬움



| 경우의수 | 중복 | 순서 |
| :------: | :--: | :--: |
|   순열   |  X   |  O   |
| 중복순열 |  O   |  O   |
|   조합   |  X   |  X   |
| 중복조합 |  O   |  X   |



## 확률



















### 기술통계(Descriptive statistics)

측정이나 실험에서 수집한 자료의 정리, 표현, 요약, 해석 등을 통해 자료의 특성을 규명하는 통계적 방법



중심





통계적 추론(statistical inference)

: 모집단에 대한 어떤 미지의 양상을 알기 위해 통계학을 이용하여 추측하는 과정

-> 도수확률과 베이즈 추론 으로 나뉨

추정과 가설검정으로 나뉨

추정은 표본을 통해 모집단 특성이 어떠한가에 대해 추측

가설검정은 추정에 의해 나온 주장을 표본이 가지고 있는 정보를 이용해 가설이 올바른지 판정하는 과정







베이즈 확률론

확률을 '지식 또는 믿음의 정도를 나타내는 양'으로 해석하는 확률론

H : 가설

D : 데이터

사후확률$P(H|D)$ = 사전확률$P(H)$ * 가능도$P(D|H)$

$$
P(H|D) = \frac{P(D|H)P(H)}{P(D)}
$$



베이지안 추론(베이즈추론)(Bayesian inference)

추론 대상의 사전 확률과 추가적인 정보를 통해 해당 대상의 사후 확률을 추론하는 방법이다. 추론하는 대상을 확률변수로 보아 그 변수의 확률분포를 추정하는 것

베이즈 추론에서는 추론 대상($\theta$)에 대하여, $\theta$에대한 사전 확률 $p(\theta)$가 주어진다. $\theta$와 관계된 관측 X의 확률 분포가 $p(X|\theta)$와 같이 주어진다고 할 때, 베이즈 추론은 X가 추가적으로 주어졌을 떄의 $\theta$의 분포 $p(\theta|X)$는 베이즈 정리를 이용하여 다음과 같이 계산할 수 있다.
$$
p(\theta|X) = \frac{p(\theta,X)}{p(X)} = \frac{p(X|\theta)p(\theta)}{p(X)}
$$

$$
\begin{align}P(A)\end{align}
$$


parameter

statistic

estimate



posterior

prior

ikelihood

marginal









베르누이시행

독립시행



독립조건





선형회기식
$$
y ~ \omega x +
$$















기술통계

대표값

산포지표



중앙값





산술평균

기하평균

조화평균

-> 비율의평균, 속도평균
$$
\frac{1}{v_m} = \frac{1}{2} \Big{(} \frac{1}{v_1} + \frac{1}{v_2} \Big{)}
$$



분산


$$
Variance(x) = \frac{1}{N} \sum^N_{i=1} (x_i - \bar{x})^2
$$




켤레사전분포conjugate

평균을 사용하면 - 변동서의 척도는 분산, 표준편차

중앙값(median) - IQR(x)

50퍼센트 준위수 -> 퍼센테이지를 4분해서 분위수

IQR = Q3 -Q1

Boxplot

Q1 - IQR*1.5 를 벗어나는 

Q3 + IQR * 1.5 를 벗어나면 이상치로 약속







변동계수 std(x) / \bar{x}





min-max scaling

standardization

nomalization(roburst scaling)4분위 편차계수





공분산과 상관계수

x와 y데이터의 분산을 





기울기방향 두께는 두변수 산포

수직한방향의 두께는 두변수간 상관관계







적률



왜도 



첨도

3보다 크면 안댐





정규분포로 만드는법

로그변환 박스코스변환





피어슨 상관계수





주성분분석



















확률변수

실험에의해서 얻어진 값들



DRV

연속확률변수(CRV)







확률분포



이항분포

드림클래스분포









스태너리 아리마 -> 빈도주의

강화학습 -> 베지안





















numpy정리

vstack

hstack











qnorm

rnorm

dnorm





카이제곱분포

분산은 알고 평균은 모를때



t-분포

표본의 평균이 갖는 분포

평균은 아는데 분산을 모를때

모평균을 추정함







































y = ax + b를 본적이 있다

y에관한 x의 1차 방정식

여기서 주어진것은 x의 계수인 a와 상수 b

우리가 구하는것은 y의 값이었다.



머신러닝, 선형회기에서는 모든문제를 여러변수의 1차 방정식으로 만들어서

y(나중에 예측할)값과 여러개의 x_i(데이터)값이 주어져있으면 이를 모델로 가장 적합한 변수를 찾아간다.

상수마저 x_i가 1이고 계수가 있는 것으로 변환해서

y = w * X + 오차



경사하강법



모멘텀

네스테로프 모멘텀



데이터 셋을 batch size만큼 쪼개서 

에포크 : 모든데이터셋을 몇번 학습할것인지







로스가 가장 작은 w를 찾아가는방법을































numpy



series

= index + 1d array

dataframe

= index + columns + 2d array

= series 들















