---

---

# 통계

## 경우의 수

### 순열(Permutation)

**서로 다른** n개의 원소에서 **중복없이** r개를 **순서에 상관있게** 택하는 방법
$$
\begin{align}
_nP_r &= n \cdot _{n-1}P_{r-1} \\
&= n \times (n-1) \times (n-2) \times \dots \times (n - r + 1) \\
&= \frac{n!}{(n-r)!}
\end{align}
$$



### 중복순열

**서로 다른** n개의 원소에서 **중복을 허락**하여 r개를 **순서에 상관있게**택하는 방법
$$
_n\Pi_r = n^r
$$



### 조합(Combination)

**서로 다른** n개의 원소에서 **중복없이** r개를 **순서에 상관없이** r개를 택하는 방법
$$
_nC_r = \frac{_nP_r}{r!} = \frac{n!}{(n-r)!r!}
$$



### 중복조합

**서로 다른** n개의 원소에서 **중복을 허락**하여 r개를 **순서에 상관없이** 택하는 조합
$$
\begin{align}
_nH_r = _{n+r-1}C_r
\end{align}
$$



n개의 원소와 분류하는 칸막이 r-1개를 나열한다고 생각하면 쉬움



| 경우의수 | 중복 | 순서 |
| :------: | :--: | :--: |
|   순열   |  X   |  O   |
| 중복순열 |  O   |  O   |
|   조합   |  X   |  X   |
| 중복조합 |  O   |  X   |



## 확률



















### 기술통계(Descriptive statistics)

측정이나 실험에서 수집한 자료의 정리, 표현, 요약, 해석 등을 통해 자료의 특성을 규명하는 통계적 방법



중심





통계적 추론(statistical inference)

: 모집단에 대한 어떤 미지의 양상을 알기 위해 통계학을 이용하여 추측하는 과정

-> 도수확률과 베이즈 추론 으로 나뉨

추정과 가설검정으로 나뉨

추정은 표본을 통해 모집단 특성이 어떠한가에 대해 추측

가설검정은 추정에 의해 나온 주장을 표본이 가지고 있는 정보를 이용해 가설이 올바른지 판정하는 과정







베이즈 확률론

확률을 '지식 또는 믿음의 정도를 나타내는 양'으로 해석하는 확률론

H : 가설

D : 데이터

사후확률$$P(H|D)$$ = 사전확률$$P(H)$$ * 가능도$$P(D|H)$$
$$
P(H|D) = \frac{P(D|H)P(H)}{P(D)}
$$



베이지안 추론(베이즈추론)(Bayesian inference)

추론 대상의 사전 확률과 추가적인 정보를 통해 해당 대상의 사후 확률을 추론하는 방법이다. 추론하는 대상을 확률변수로 보아 그 변수의 확률분포를 추정하는 것

베이즈 추론에서는 추론 대상($$\theta$$)에 대하여, $$\theta$$에대한 사전 확률 $$p(\theta)$$가 주어진다. $$\theta$$와 관계된 관측 X의 확률 분포가 $$p(X|\theta)$$와 같이 주어진다고 할 때, 베이즈 추론은 X가 추가적으로 주어졌을 떄의 $$\theta$$의 분포 $$p(\theta|X)$$는 베이즈 정리를 이용하여 다음과 같이 계산할 수 있다.
$$
p(\theta|X) = \frac{p(\theta,X)}{p(X)} = \frac{p(X|\theta)p(\theta)}{p(X)}
$$

$$
\begin{align}P(A)\end{align}
$$


parameter

statistic

estimate



posterior

prior

ikelihood

marginal









베르누이시행

독립시행



독립조건





선형회기식
$$
y ~ \omega x +
$$















기술통계

대표값

산포지표



중앙값





산술평균

기하평균

조화평균

-> 비율의평균, 속도평균
$$
\frac{1}{v_m} = \frac{1}{2} \Big{(} \frac{1}{v_1} + \frac{1}{v_2} \Big{)}
$$



분산


$$
Variance(x) = \frac{1}{N} \sum^N_{i=1} (x_i - \bar{x})^2
$$




켤레사전분포conjugate

평균을 사용하면 - 변동서의 척도는 분산, 표준편차

중앙값(median) - IQR(x)

50퍼센트 준위수 -> 퍼센테이지를 4분해서 분위수

IQR = Q3 -Q1

Boxplot

Q1 - IQR*1.5 를 벗어나는 

Q3 + IQR * 1.5 를 벗어나면 이상치로 약속







변동계수 std(x) / \bar{x}





min-max scaling

standardization

nomalization(roburst scaling)4분위 편차계수





공분산과 상관계수

x와 y데이터의 분산을 





기울기방향 두께는 두변수 산포

수직한방향의 두께는 두변수간 상관관계







적률



왜도 



첨도

3보다 크면 안댐





정규분포로 만드는법

로그변환 박스코스변환





피어슨 상관계수





주성분분석



















확률변수

실험에의해서 얻어진 값들



DRV

연속확률변수(CRV)







확률분포



이항분포

드림클래스분포









스태너리 아리마 -> 빈도주의

강화학습 -> 베지안





















numpy정리

vstack

hstack











qnorm

rnorm

dnorm





카이제곱분포

분산은 알고 평균은 모를때



t-분포

표본의 평균이 갖는 분포

평균은 아는데 분산을 모를때

모평균을 추정함







































y = ax + b를 본적이 있다

y에관한 x의 1차 방정식

여기서 주어진것은 x의 계수인 a와 상수 b

우리가 구하는것은 y의 값이었다.



머신러닝, 선형회기에서는 모든문제를 여러변수의 1차 방정식으로 만들어서

y(나중에 예측할)값과 여러개의 x_i(데이터)값이 주어져있으면 이를 모델로 가장 적합한 변수를 찾아간다.

상수마저 x_i가 1이고 계수가 있는 것으로 변환해서

y = w * X + 오차



경사하강법



모멘텀

네스테로프 모멘텀



데이터 셋을 batch size만큼 쪼개서 

에포크 : 모든데이터셋을 몇번 학습할것인지







로스가 가장 작은 w를 찾아가는방법을































numpy



series

= index + 1d array

dataframe

= index + columns + 2d array

= series 들









































## 탐색적 데이터 분석

데이터의 종류

- 연속형 : 일정 범위 안에 어떤 값이든 취할 수 있는 데이터 (구간,실수,수치 형)
- 이산 : 정수 값만 취함 (정수형, 횟수)
- 범주형 : 범주 안의 값 (목록, 열거, 등)
- 이진 : 두개의 값만 갖는 범주형 데이터 (이항적, 논리형)
- 순서형 : 값들 사이에 분명한 순위가 있는 범주형 데이터

데이터 처리를 위해 남/여 같은 이진 데이터도 0/1 같이 수치화 해줘야한다.

테이블 데이터 용어

- 데이터 프레임 : 통계와 머신러닝 모델의 기본이되는 테이블 형태의 데이터 구조
- 피처 : 테이블의 각 열 하나 (특징, 속성, 입력, 예측변수)
- 결과 : (종속변수, 응답, 출력)
- 레코드 : 테이블의 각 행 (기록값, 사건, 관측값)



### 위치 추정

데이터를 살펴보는 방법의 기초적 단계는 '대표값(typical value)'를 구하는 것

대푯값: 대부분의 값이 어디쯤에 위치하는지 나타내는 추정값

- 평균(mean)
- 가중평균 : 가중치를 곱한 값의 총합을 가중치의 총합으로 나눈 값
- 중간값(median) : 데이터에서 가장 가운데 위치한 값 (50번쨰 백분위수)
- 가중 중간값 : 데이터 정렬 후 각 가중치 값을 더해서 총합의 중간이 위치하는 데이터 값
- 절사평균 : 극단값을 제외한 나머지 값의 평균

로버스트하다 : 극단값들에 민감하지 않다 (저항성 있다)

특잇값 : 대부분의 값과 매우 다른 데이터값 (극단값)

극단값은 데이터 분석에 있어 유익한 정보를 제공할때도 있고, 골칫거리가 되기도 한다. 평균은 계산하기 쉽고 사용하기 편하지만 극단값의 영향을 많이 받는다. 그래서 보다 전사평균, 가중평균이 더 합리적일 수 있다. 또한 중간값은 데이터의 민감도가 낮기 떄문에 특잇값에 로버스트하다.

산포지표(variability) : 데이터의 산포도(dispersion)을 나타내줌

- 편차(deviation) : 관측값과 위치 추정값사이의 차이 (오차, 잔차)
- 분산(variance) : 편균과의 편차를 제곱한 값들의 합을 (데이터개수-1)로 나눈값
- 표준편차 : 분산의 제곱근
- 평균 절대 편차 : 평균과의 편차의 절댓값 평균
- 중앙값 절대편차(MAD) : 중간값과의 편차의 절댓값의 중간값
- 백분위수(percentile) : 어떤 값들을 정렬했을 때 위치하는 순서를 백분위로 나타낸 값 
- 사분위범위(IQR) : 75 백분위수와 25 백분위수 의 차이



표본 분산을 구할때 n-1을 나누는 이유는 자유도(DOF) 때문이다. 표준편차는 표본의 평균에 따른다는 제약 조건을 가지고 있기 때문에 n-1의 자유도를 갖는다. 이를 자세히 알기위해서는 다소 많은 시간을 투자해야하므로 직관적으로 이해하고 넘어간다. 표본집단의 분산으로 모집단의 분산을 추정할때는 n대신 n-1을 나눠야 비편향(unbiased) 추정이라고 알아두고 넘어간다.

표준편차는 원래데이터와 같은 scale에 있고, 수학적으로 제곱한 값이 절댓값보다 통계 모델을 다루는데 더 편리하기때문에 통계에서는 표준편차를 선호한다.

분산, 표준편차, 평균절대편차는 모두 극단값에 로버스트하지 않다. 로버스트한 변위 추정값으로는 MAD, IQR가 있다. 변위(산포지표)를 측정하는 가장 대표적인 방법은 사분위범위(IQR) 이다.

데이터가 매우클때 IQR은 정렬해야하기때문에 연산이 많이필요하다. 그래서 실제로 소프트웨어로 근사값을 이용하는데 꽤 높은 정확도를 보장한다고한다.



데이터 분포를 그래프로 나타내는 방법

- 상자그림boxplot
- 도수분포표frequency table
- 히스토그램histogram
- 밀도 그림density plot



이차, 삼차 모멘트

- 왜도skewness : 데이터가 큰 값이나 작은 값 쪽으로 얼마나 비스듬히 쏠려 있는지 나타내는 값
- 첨도kurtosis : 데이터가 극단값을 갖는 경향성



이진데이터와 범주 데이터 탐색

- 최빈값mode
- 기댓값 : 범주의 출현 확률에 따른 평균
- 막대도표
- 파이그림

범주형 데이터는 비율로 요약하고, 막대도표로 나타낸다.



상관관계

- 상관계수
- 산점도

